{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mviana123/Exotransit/blob/main/live_coding/2_function_approximation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErJV9S8NChuq"
      },
      "source": [
        "# Function Approximation\n",
        "- Function takes an input, and gives an output\n",
        "  - $f(x) = y$\n",
        "- Everything in the world can be regarded as a function\n",
        "- And Neural Network can approximate many functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K89yBL1BqnI"
      },
      "source": [
        "## A. Regression with One Variable\n",
        "- Regression:\n",
        "  - Process of training a model to predict a **continuous** numerical output based on one or more input features.\n",
        "  - e.g.: Predicts the child's height based on the parent's height.\n",
        "  - Why is it named \"regression\"?:\n",
        "    - The term was first used by Sir Francis Galton, a British statistician and cousin of Charles Darwin, in the late 19th century. Galton was studying the relationship between heights of parents and their children. He observed that although tall parents often had tall children, the children's heights tended to \"regress\" towards the average or mean height of the population. Similarly, children of short parents were often short but their heights still regressed towards the average."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pqe-tWojXZd"
      },
      "source": [
        "- What is the difference between continuous and discrete?\n",
        "  - In continuous value, you can alwyas have a middle point between to given points\n",
        "    - For example, if we have 1.0 and 2.0, there exists their middle point 1.5\n",
        "    - 2.0 is twice large than 1.0\n",
        "  - On the other hand, discrete value does not have middle point\n",
        "    - Even if we have student number 20250001, 20250002, there won't be 20250001.5\n",
        "    - 20250001 and 20250002 has no meaning of size or magnitude"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6zfXa2tChus"
      },
      "source": [
        "- Let's make function that works as f(x) = ax+b\n",
        "    -  In this cell, we will create a function that follows the linear equation format f(x) = ax + b. This function will take an input x and return value that is the result of the equation. The variables a and b are coefficients that we will define. The variable a is the slope of the line and b is the y-intercept. This function will help us understand the concept of function approximation in the context of regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HkqNYWTBqnJ",
        "outputId": "d89129af-93b1-4ac1-a4f9-f5c4abea4f28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.5999999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Let's make function that works as f(x) = ax+b\n",
        "\n",
        "param_a = 1.7\n",
        "param_b = -2.3\n",
        "\n",
        "def my_function(x): # hidden function that we have to guess\n",
        "\n",
        "  return param_a * x + param_b\n",
        "\n",
        "my_function(1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qbcrAnKGDGtE"
      },
      "outputs": [],
      "source": [
        "# Let's plot this function\n",
        "# First, let's make many x candidates\n",
        "# from -5 to 5, with 500 total x\n",
        "\n",
        "xs = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVatQ4InEUQ0"
      },
      "outputs": [],
      "source": [
        "# Now, let's make y\n",
        "# y = f(x)\n",
        "ys = []\n",
        "# Using for loop\n",
        "\n",
        "# Using list comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQDsS3vnEjRu"
      },
      "outputs": [],
      "source": [
        "# Check the length of xs and ys are equal\n",
        "# The item of xs and ys are 1:1 mapping\n",
        "len(xs), len(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv58AK2kEmun"
      },
      "outputs": [],
      "source": [
        "# We can check that i-th value of xs and ys are 1:1 mapping\n",
        "# ys[idx] has to be equal to my_function(xs[idx])`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVM9X4JgK5s2"
      },
      "source": [
        "Let's plot this function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNNwVTmTpMt4"
      },
      "outputs": [],
      "source": [
        "# To plot arbitrary number of data points on 2D space, we can use plt.scatter\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuFJXe7CK5s3"
      },
      "outputs": [],
      "source": [
        "# How can we draw ony 1 sample for every 10 samples instead of drawing every samples?\n",
        "\n",
        "# in python slice indexing, you can ommit initial slice if you are selecting it from very first\n",
        "# and also end slice if you are selecting until the very last one\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmJxSsBSFKzo"
      },
      "outputs": [],
      "source": [
        "# Let's add some noise\n",
        "# adding random noise\n",
        "import random\n",
        "# random.random() # this provide a random value between 0 and 1\n",
        "# if you want to get random value bewtween -1 to 1\n",
        "# noise = (random.random() - 0.5) * 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uuc-dMbFKsx"
      },
      "outputs": [],
      "source": [
        "# plot again"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-ULt92mChuv"
      },
      "source": [
        "##### (Extra) Short Explanation about Random Number Generator\n",
        "- Random number generator is a function that generates a sequence of numbers that seem to occur in random order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU_PHZ1-F7Qg"
      },
      "outputs": [],
      "source": [
        "# random is not actually complete random\n",
        "# usually computers uses pseudo-random\n",
        "\n",
        "# random.random() in fact has its destiny. It will always return same value\n",
        "# if the seed is the same\n",
        "\n",
        "random.seed(0)\n",
        "[random.random() for _ in range(10)]\n",
        "\n",
        "# No matter how many times you run this code, it will always return same value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHeOBhEMChuw"
      },
      "source": [
        "### 1) Guess Regression manually\n",
        "- Since we know the function f(x) = ax + b, we can guess the value of a and b.\n",
        "- If we select correct a and b, the line will be the best fit line for the data.\n",
        "    - What machine learning does is to find the best a and b automatically.\n",
        "    - But here, we will find the best a and b manually, so that we can understand the concept of machine learning better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQMSHCf0HhCc"
      },
      "outputs": [],
      "source": [
        "# Let's suppose we try guessing a and b manually\n",
        "\n",
        "est_a = 0\n",
        "est_b = 0\n",
        "\n",
        "def my_estimation(x, est_a, est_b):\n",
        "  return\n",
        "\n",
        "est_ys = [my_estimation(x, est_a, est_b) for x in xs]\n",
        "\n",
        "plt.scatter(xs, ys) # coloured with blue\n",
        "plt.scatter(xs, est_ys) # coloured with orange"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvd3Q0rvChuw"
      },
      "source": [
        "#### 1-1) Calculating Error\n",
        "- How can we calculates how good or bad our estimation is?\n",
        "    - We can calculate the error between the actual value and the predicted value.\n",
        "        - There are many ways to calculate the error.\n",
        "            - For example, we can calculate the absolute value of the difference between the actual value and the predicted value.\n",
        "              - $y-\\hat{y}$\n",
        "            - Or we can calculate the square of the difference between the actual value and the predicted value.\n",
        "              - $(y-\\hat{y})^2$\n",
        "    - We call this error value as **loss**.\n",
        "        - Sometimes, we call this error as **cost**.\n",
        "    - The function that calculates the loss is called **loss function**.\n",
        "        - Sometimes, we call this loss function as **cost function** or **objective function**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWNEMo0DIh6B"
      },
      "outputs": [],
      "source": [
        "def cal_error(pred, target):\n",
        "  return\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBRLWcy9J6fH"
      },
      "outputs": [],
      "source": [
        "# compare every value in y_noise and estimation\n",
        "# we have to compare values in the same idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtQwkaNjK5s5"
      },
      "outputs": [],
      "source": [
        "# calculate loss (error) for every sample\n",
        "def get_loss(est_a, est_b, xs, ys):\n",
        "  return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U_wVFZjK8j2"
      },
      "outputs": [],
      "source": [
        "# change a and b to get better estimation\n",
        "\n",
        "est_a = -2.1\n",
        "est_b = 3.1\n",
        "\n",
        "est_ys = [my_estimation(x, est_a, est_b) for x in xs]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvNnkMhSEwQH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l2giGfRxObd"
      },
      "outputs": [],
      "source": [
        "plt.scatter(xs, ys) # coloured with blue\n",
        "plt.scatter(xs, est_ys) # coloured with orange"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}